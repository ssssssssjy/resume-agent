"""GitHub é¡¹ç›®æ·±åº¦åˆ†æå·¥å…·

æ·±å…¥åˆ†æ GitHub ä»“åº“çš„æŠ€æœ¯æ ˆã€æ¶æ„ç‰¹ç‚¹ã€æ ¸å¿ƒåŠŸèƒ½ç­‰ï¼Œ
ä¸ºç®€å†æä¾›å¯å‚è€ƒçš„æŠ€æœ¯ç»†èŠ‚å’Œé‡åŒ–æŒ‡æ ‡ã€‚

è¿”å›ç®€æ´æ‘˜è¦ + è¯¦ç»†æ–‡æ¡£å†…å®¹ï¼ˆä¾› Agent ä½¿ç”¨ write_file ä¿å­˜ï¼‰ã€‚
"""
import logging
from typing import Any

import requests

from ._internal import format_repo_analysis_document, get_document_path, get_github_headers

logger = logging.getLogger(__name__)

GITHUB_API_BASE = "https://api.github.com"


async def analyze_github_repo(repo: str) -> dict[str, Any]:
    """æ·±åº¦åˆ†æ GitHub ä»“åº“

    è·å–ä»“åº“çš„æŠ€æœ¯æ ˆã€æ¶æ„äº®ç‚¹ã€æ ¸å¿ƒåŠŸèƒ½ã€è´¡çŒ®è€…æ´»è·ƒåº¦ç­‰ä¿¡æ¯ï¼Œ
    ä¸ºç®€å†ä¼˜åŒ–æä¾›æŠ€æœ¯ç»†èŠ‚å‚è€ƒã€‚

    Args:
        repo: ä»“åº“åç§°ï¼Œæ ¼å¼ä¸º "owner/repo" (å¦‚ "langchain-ai/langgraph")

    Returns:
        åŒ…å«ç®€æ´æ‘˜è¦å’Œæ–‡æ¡£å†…å®¹çš„å­—å…¸ï¼š
        - summary: ç®€æ´çš„åˆ†æç»“æœæ‘˜è¦
        - document_content: è¯¦ç»†çš„ Markdown æ–‡æ¡£å†…å®¹
        - suggested_path: å»ºè®®ä¿å­˜è·¯å¾„
    """
    result = {
        "repo": repo,
        "basic_info": {},
        "tech_stack": [],
        "architecture_highlights": [],
        "key_features": [],
        "metrics": {},
        "readme_summary": "",
        "recent_activity": [],
        "error": None,
    }

    try:
        # 1. è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯
        repo_info = await _get_repo_info(repo)
        if "error" in repo_info:
            result["error"] = repo_info["error"]
            return result

        result["basic_info"] = {
            "name": repo_info.get("full_name", ""),
            "description": repo_info.get("description", ""),
            "homepage": repo_info.get("homepage", ""),
            "topics": repo_info.get("topics", []),
            "license": repo_info.get("license", {}).get("name", "Unknown"),
            "created_at": repo_info.get("created_at", ""),
            "updated_at": repo_info.get("updated_at", ""),
        }

        result["metrics"] = {
            "stars": repo_info.get("stargazers_count", 0),
            "forks": repo_info.get("forks_count", 0),
            "watchers": repo_info.get("subscribers_count", 0),
            "open_issues": repo_info.get("open_issues_count", 0),
            "size_kb": repo_info.get("size", 0),
        }

        # 2. è·å–è¯­è¨€åˆ†å¸ƒï¼ˆæŠ€æœ¯æ ˆï¼‰
        languages = await _get_languages(repo)
        if languages:
            total_bytes = sum(languages.values())
            result["tech_stack"] = [
                {
                    "language": lang,
                    "percentage": round(bytes_count / total_bytes * 100, 1),
                    "bytes": bytes_count,
                }
                for lang, bytes_count in sorted(languages.items(), key=lambda x: x[1], reverse=True)
            ]

        # 3. è·å–è´¡çŒ®è€…ä¿¡æ¯
        contributors = await _get_contributors(repo)
        result["metrics"]["contributors"] = len(contributors)
        result["metrics"]["top_contributors"] = [
            {"login": c.get("login", ""), "contributions": c.get("contributions", 0)}
            for c in contributors[:5]
        ]

        # 4. è·å–æœ€è¿‘çš„æäº¤æ´»åŠ¨
        commits = await _get_recent_commits(repo)
        result["recent_activity"] = commits
        if commits:
            result["metrics"]["commit_frequency"] = f"{len(commits)} commits in last 30 days"

        # 5. è·å– README å¹¶æå–æ‘˜è¦
        readme = await _get_readme(repo)
        if readme:
            result["readme_summary"] = _extract_readme_summary(readme)
            result["key_features"] = _extract_features_from_readme(readme)
            result["architecture_highlights"] = _extract_architecture_from_readme(readme)

        # 6. è·å–ä»“åº“çš„ releases ä¿¡æ¯
        releases = await _get_releases(repo)
        if releases:
            result["metrics"]["latest_release"] = releases[0].get("tag_name", "")
            result["metrics"]["total_releases"] = len(releases)

    except Exception as e:
        logger.error(f"åˆ†æä»“åº“ {repo} å¤±è´¥: {e}")
        result["error"] = str(e)

    # ç”Ÿæˆæ–‡æ¡£å†…å®¹å’Œç®€æ´æ‘˜è¦
    document_content = format_repo_analysis_document(repo, result)
    suggested_path = get_document_path("repo_analysis", repo)
    summary = _format_summary(repo, result, suggested_path)

    return {
        "summary": summary,
        "document_content": document_content,
        "suggested_path": suggested_path,
    }


def _format_summary(repo: str, result: dict, suggested_path: str) -> str:
    """ç”Ÿæˆç®€æ´çš„åˆ†æç»“æœæ‘˜è¦"""
    if result.get("error"):
        return f"åˆ†æå¤±è´¥ï¼š{result['error']}"

    lines = []

    # åŸºæœ¬ä¿¡æ¯
    basic = result.get("basic_info", {})
    metrics = result.get("metrics", {})

    lines.append(f"**{repo}** åˆ†æå®Œæˆ")
    lines.append("")

    # æ ¸å¿ƒæŒ‡æ ‡
    lines.append("**æ ¸å¿ƒæŒ‡æ ‡ï¼š**")
    lines.append(f"- â­ Stars: {metrics.get('stars', 0):,}")
    lines.append(f"- ğŸ´ Forks: {metrics.get('forks', 0):,}")
    lines.append(f"- ğŸ‘¥ è´¡çŒ®è€…: {metrics.get('contributors', 0)}")
    if metrics.get("latest_release"):
        lines.append(f"- ğŸ“¦ æœ€æ–°ç‰ˆæœ¬: {metrics['latest_release']}")
    lines.append("")

    # æŠ€æœ¯æ ˆ
    tech_stack = result.get("tech_stack", [])
    if tech_stack:
        top_langs = [f"{t['language']} ({t['percentage']}%)" for t in tech_stack[:3]]
        lines.append(f"**æŠ€æœ¯æ ˆï¼š** {', '.join(top_langs)}")
        lines.append("")

    # æ ¸å¿ƒåŠŸèƒ½
    features = result.get("key_features", [])
    if features:
        lines.append("**æ ¸å¿ƒåŠŸèƒ½ï¼š**")
        for f in features[:3]:
            lines.append(f"- {f[:60]}...")
        lines.append("")

    # ä¿å­˜æç¤º
    lines.append(f"è¯·ä½¿ç”¨ write_file å°†è¯¦ç»†æŠ¥å‘Šä¿å­˜åˆ° `{suggested_path}`")

    return "\n".join(lines)


async def _get_repo_info(repo: str) -> dict:
    """è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯"""
    try:
        url = f"{GITHUB_API_BASE}/repos/{repo}"
        response = requests.get(url, headers=get_github_headers(), timeout=10)
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            return {"error": f"ä»“åº“ {repo} ä¸å­˜åœ¨"}
        else:
            return {"error": f"GitHub API é”™è¯¯: {response.status_code}"}
    except Exception as e:
        return {"error": str(e)}


async def _get_languages(repo: str) -> dict:
    """è·å–ä»“åº“è¯­è¨€åˆ†å¸ƒ"""
    try:
        url = f"{GITHUB_API_BASE}/repos/{repo}/languages"
        response = requests.get(url, headers=get_github_headers(), timeout=10)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        logger.warning(f"è·å–è¯­è¨€åˆ†å¸ƒå¤±è´¥: {e}")
    return {}


async def _get_contributors(repo: str, max_count: int = 30) -> list:
    """è·å–è´¡çŒ®è€…åˆ—è¡¨"""
    try:
        url = f"{GITHUB_API_BASE}/repos/{repo}/contributors"
        params = {"per_page": max_count}
        response = requests.get(url, headers=get_github_headers(), params=params, timeout=10)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        logger.warning(f"è·å–è´¡çŒ®è€…å¤±è´¥: {e}")
    return []


async def _get_recent_commits(repo: str, days: int = 30) -> list:
    """è·å–æœ€è¿‘çš„æäº¤è®°å½•"""
    try:
        from datetime import datetime, timedelta
        since = (datetime.utcnow() - timedelta(days=days)).isoformat() + "Z"

        url = f"{GITHUB_API_BASE}/repos/{repo}/commits"
        params = {"since": since, "per_page": 100}
        response = requests.get(url, headers=get_github_headers(), params=params, timeout=10)
        if response.status_code == 200:
            commits = response.json()
            return [
                {
                    "sha": c.get("sha", "")[:7],
                    "message": c.get("commit", {}).get("message", "").split("\n")[0][:80],
                    "author": c.get("commit", {}).get("author", {}).get("name", ""),
                    "date": c.get("commit", {}).get("author", {}).get("date", ""),
                }
                for c in commits[:10]  # åªè¿”å›æœ€è¿‘ 10 æ¡
            ]
    except Exception as e:
        logger.warning(f"è·å–æäº¤è®°å½•å¤±è´¥: {e}")
    return []


async def _get_readme(repo: str) -> str:
    """è·å– README å†…å®¹"""
    try:
        url = f"{GITHUB_API_BASE}/repos/{repo}/readme"
        headers = get_github_headers()
        headers["Accept"] = "application/vnd.github.v3.raw"
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            return response.text
    except Exception as e:
        logger.warning(f"è·å– README å¤±è´¥: {e}")
    return ""


async def _get_releases(repo: str, max_count: int = 10) -> list:
    """è·å–å‘å¸ƒç‰ˆæœ¬åˆ—è¡¨"""
    try:
        url = f"{GITHUB_API_BASE}/repos/{repo}/releases"
        params = {"per_page": max_count}
        response = requests.get(url, headers=get_github_headers(), params=params, timeout=10)
        if response.status_code == 200:
            releases = response.json()
            return [
                {
                    "tag_name": r.get("tag_name", ""),
                    "name": r.get("name", ""),
                    "published_at": r.get("published_at", ""),
                    "prerelease": r.get("prerelease", False),
                }
                for r in releases
            ]
    except Exception as e:
        logger.warning(f"è·å– releases å¤±è´¥: {e}")
    return []


def _extract_readme_summary(readme: str, max_length: int = 500) -> str:
    """ä» README ä¸­æå–æ‘˜è¦"""
    if not readme:
        return ""

    lines = readme.split("\n")
    summary_lines = []
    in_code_block = False
    char_count = 0

    for line in lines:
        # è·³è¿‡ä»£ç å—
        if line.strip().startswith("```"):
            in_code_block = not in_code_block
            continue
        if in_code_block:
            continue

        # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆä½†ä¿ç•™ç¬¬ä¸€ä¸ªæ ‡é¢˜åçš„å†…å®¹ï¼‰
        if line.startswith("#"):
            continue

        # è·³è¿‡å¾½ç« è¡Œ
        if "![" in line or "[![" in line:
            continue

        # è·³è¿‡ç©ºè¡Œï¼ˆè¿ç»­çš„ç©ºè¡Œåªä¿ç•™ä¸€ä¸ªï¼‰
        if not line.strip():
            if summary_lines and summary_lines[-1].strip():
                summary_lines.append("")
            continue

        # ç´¯åŠ å†…å®¹
        summary_lines.append(line)
        char_count += len(line)

        if char_count >= max_length:
            break

    return "\n".join(summary_lines).strip()[:max_length]


def _extract_features_from_readme(readme: str) -> list[str]:
    """ä» README ä¸­æå–å…³é”®åŠŸèƒ½"""
    features = []
    lines = readme.split("\n")

    in_features_section = False
    feature_keywords = ["feature", "åŠŸèƒ½", "ç‰¹æ€§", "highlights", "what", "why"]

    for i, line in enumerate(lines):
        line_lower = line.lower()

        # æ£€æµ‹æ˜¯å¦è¿›å…¥ features éƒ¨åˆ†
        if line.startswith("#") and any(kw in line_lower for kw in feature_keywords):
            in_features_section = True
            continue

        # å¦‚æœé‡åˆ°æ–°çš„æ ‡é¢˜ï¼Œé€€å‡º features éƒ¨åˆ†
        if in_features_section and line.startswith("#"):
            break

        # æå–åˆ—è¡¨é¡¹
        if in_features_section:
            stripped = line.strip()
            if stripped.startswith(("- ", "* ", "â€¢ ")):
                feature = stripped[2:].strip()
                if feature and len(feature) > 5:
                    # æ¸…ç† markdown æ ¼å¼
                    feature = feature.replace("**", "").replace("*", "").replace("`", "")
                    features.append(feature[:100])  # é™åˆ¶é•¿åº¦

                    if len(features) >= 10:
                        break

    return features


def _extract_architecture_from_readme(readme: str) -> list[str]:
    """ä» README ä¸­æå–æ¶æ„äº®ç‚¹"""
    highlights = []
    lines = readme.split("\n")

    arch_keywords = ["architecture", "design", "how it works", "æ¦‚è¿°", "æ¶æ„", "è®¾è®¡", "åŸç†", "implementation"]

    in_arch_section = False

    for line in lines:
        line_lower = line.lower()

        # æ£€æµ‹æ¶æ„ç›¸å…³éƒ¨åˆ†
        if line.startswith("#") and any(kw in line_lower for kw in arch_keywords):
            in_arch_section = True
            continue

        if in_arch_section and line.startswith("#"):
            break

        if in_arch_section:
            stripped = line.strip()
            # æå–å…³é”®æè¿°ï¼ˆéç©ºè¡Œï¼Œéä»£ç ï¼Œæœ‰æ„ä¹‰çš„å†…å®¹ï¼‰
            if stripped and not stripped.startswith(("```", "![", "<")):
                if len(stripped) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    clean = stripped.replace("**", "").replace("*", "").replace("`", "")
                    highlights.append(clean[:150])

                    if len(highlights) >= 5:
                        break

    return highlights
