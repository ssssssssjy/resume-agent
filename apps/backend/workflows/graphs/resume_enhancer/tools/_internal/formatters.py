"""æ–‡æ¡£æ ¼å¼åŒ–å·¥å…·ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰

å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º Markdown æ–‡æ¡£ã€‚
"""
from datetime import datetime
from typing import Any

# æ–‡æ¡£ä¿å­˜æ ¹ç›®å½•
REFERENCES_DIR = "/references"


def get_document_path(doc_type: str, identifier: str) -> str:
    """ç”Ÿæˆæ–‡æ¡£ä¿å­˜è·¯å¾„

    Args:
        doc_type: æ–‡æ¡£ç±»å‹ (tech_trends, tech_articles, repo_analysis)
        identifier: æ ‡è¯†ç¬¦ï¼ˆæŠ€æœ¯åã€ä»“åº“åç­‰ï¼‰

    Returns:
        æ–‡æ¡£è·¯å¾„ï¼Œå¦‚ /references/tech_trends_RAG.md
    """
    safe_identifier = identifier.replace("/", "_").replace(" ", "_").replace(",", "_")
    safe_identifier = "".join(c for c in safe_identifier if c.isalnum() or c in "_-")
    return f"{REFERENCES_DIR}/{doc_type}_{safe_identifier}.md"


def format_tech_trends_document(
    technologies: list[str],
    results: dict[str, Any],
) -> str:
    """å°†æŠ€æœ¯è¶‹åŠ¿æŸ¥è¯¢ç»“æœæ ¼å¼åŒ–ä¸º Markdown æ–‡æ¡£"""
    lines = [
        f"# æŠ€æœ¯è¶‹åŠ¿åˆ†æï¼š{', '.join(technologies)}",
        f"",
        f"> ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"",
    ]

    # ç»¼åˆæ¨è
    if results.get("recommendations"):
        lines.append("## ç®€å†å»ºè®®")
        lines.append("")
        for rec in results["recommendations"]:
            lines.append(f"- {rec}")
        lines.append("")

    # å„æŠ€æœ¯è¯¦æƒ…
    for tech_data in results.get("technologies", []):
        name = tech_data.get("name", "")
        lines.append(f"## {name}")
        lines.append("")

        # GitHub æ•°æ®
        github = tech_data.get("github", {})
        if github and not github.get("error"):
            lines.append("### GitHub çƒ­åº¦")
            lines.append(f"- ç›¸å…³ä»“åº“æ•°ï¼š{github.get('total_repos_found', 0):,}")
            lines.append(f"- Top10 æ€» Starsï¼š{github.get('total_stars_top10', 0):,}")
            lines.append(f"- æ´»è·ƒåº¦è¯„åˆ†ï¼š{github.get('activity_score', 0):.1f}%")
            lines.append("")

            top_repos = github.get("top_repos", [])
            if top_repos:
                lines.append("**çƒ­é—¨ä»“åº“ï¼š**")
                for repo in top_repos[:3]:
                    lines.append(f"- [{repo['name']}](https://github.com/{repo['name']}) â­ {repo['stars']:,}")
                    if repo.get("description"):
                        lines.append(f"  - {repo['description']}")
                lines.append("")

        # Stack Overflow æ•°æ®
        so = tech_data.get("stackoverflow", {})
        if so and not so.get("error") and so.get("question_count", 0) > 0:
            lines.append("### Stack Overflow")
            lines.append(f"- é—®é¢˜æ•°ï¼š{so.get('question_count', 0):,}")
            if so.get("related_tags"):
                lines.append(f"- ç›¸å…³æ ‡ç­¾ï¼š{', '.join(so['related_tags'])}")
            lines.append("")

        # åŒ…ä¸‹è½½æ•°æ®
        packages = tech_data.get("packages", {})
        if packages:
            npm = packages.get("npm", {})
            pypi = packages.get("pypi", {})
            if npm or pypi:
                lines.append("### åŒ…ç®¡ç†å™¨")
                if npm and npm.get("weekly_downloads"):
                    lines.append(f"- npm å‘¨ä¸‹è½½é‡ï¼š{npm['weekly_downloads']:,}")
                if pypi and pypi.get("latest_version"):
                    lines.append(f"- PyPI æœ€æ–°ç‰ˆæœ¬ï¼š{pypi['latest_version']}")
                lines.append("")

    # å¯¹æ¯”æ•°æ®
    comparison = results.get("comparison", {})
    if comparison.get("by_github_stars"):
        lines.append("## æŠ€æœ¯å¯¹æ¯”")
        lines.append("")
        lines.append("| æŠ€æœ¯ | GitHub Stars | æ´»è·ƒåº¦ |")
        lines.append("|------|-------------|--------|")
        for item in comparison["by_github_stars"]:
            lines.append(f"| {item['name']} | {item['total_stars']:,} | {item.get('activity_score', 0):.1f}% |")
        lines.append("")

    return "\n".join(lines)


def format_tech_articles_document(
    keywords: list[str],
    articles: list[dict[str, Any]],
) -> str:
    """å°†æŠ€æœ¯æ–‡ç« æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º Markdown æ–‡æ¡£"""
    lines = [
        f"# æŠ€æœ¯æ–‡ç« å‚è€ƒï¼š{', '.join(keywords)}",
        f"",
        f"> ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"> æ–‡ç« æ•°é‡ï¼š{len(articles)}",
        f"",
    ]

    if not articles:
        lines.append("*æœªæ‰¾åˆ°ç›¸å…³æ–‡ç« *")
        return "\n".join(lines)

    # æŒ‰æ¥æºåˆ†ç»„
    by_source = {}
    for article in articles:
        source = article.get("source", "å…¶ä»–")
        if source not in by_source:
            by_source[source] = []
        by_source[source].append(article)

    for source, source_articles in by_source.items():
        lines.append(f"## {source}")
        lines.append("")
        for article in source_articles:
            title = article.get("title", "æ— æ ‡é¢˜")
            url = article.get("url", "")
            summary = article.get("summary", "")
            author = article.get("author", "")
            reactions = article.get("reactions", 0)
            tags = article.get("tags", [])

            lines.append(f"### [{title}]({url})")
            if author:
                lines.append(f"*ä½œè€…ï¼š{author}* | ğŸ‘ {reactions}")
            if summary:
                lines.append(f"")
                lines.append(f"> {summary}")
            if tags:
                lines.append(f"")
                lines.append(f"æ ‡ç­¾ï¼š{', '.join(tags[:5])}")
            lines.append("")

    # å…³é”®è¯æå–å»ºè®®
    lines.append("## ç®€å†å…³é”®è¯å»ºè®®")
    lines.append("")
    lines.append("ä»ä»¥ä¸Šæ–‡ç« ä¸­å¯æå–çš„æŠ€æœ¯å…³é”®è¯ï¼š")
    all_tags = []
    for article in articles:
        all_tags.extend(article.get("tags", []))
    unique_tags = list(set(all_tags))[:10]
    if unique_tags:
        lines.append(f"- {', '.join(unique_tags)}")
    lines.append("")

    return "\n".join(lines)


def format_repo_analysis_document(
    repo: str,
    results: dict[str, Any],
) -> str:
    """å°† GitHub ä»“åº“åˆ†æç»“æœæ ¼å¼åŒ–ä¸º Markdown æ–‡æ¡£"""
    lines = [
        f"# é¡¹ç›®åˆ†æï¼š{repo}",
        f"",
        f"> ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"",
    ]

    if results.get("error"):
        lines.append(f"*åˆ†æå¤±è´¥ï¼š{results['error']}*")
        return "\n".join(lines)

    # åŸºæœ¬ä¿¡æ¯
    basic = results.get("basic_info", {})
    if basic:
        lines.append("## é¡¹ç›®æ¦‚è§ˆ")
        lines.append("")
        if basic.get("description"):
            lines.append(f"**æè¿°**ï¼š{basic['description']}")
            lines.append("")
        if basic.get("homepage"):
            lines.append(f"**ä¸»é¡µ**ï¼š{basic['homepage']}")
        if basic.get("license"):
            lines.append(f"**è®¸å¯è¯**ï¼š{basic['license']}")
        if basic.get("topics"):
            lines.append(f"**æ ‡ç­¾**ï¼š{', '.join(basic['topics'])}")
        lines.append("")

    # æŒ‡æ ‡
    metrics = results.get("metrics", {})
    if metrics:
        lines.append("## é¡¹ç›®æŒ‡æ ‡")
        lines.append("")
        lines.append(f"- â­ Starsï¼š{metrics.get('stars', 0):,}")
        lines.append(f"- ğŸ´ Forksï¼š{metrics.get('forks', 0):,}")
        lines.append(f"- ğŸ‘€ Watchersï¼š{metrics.get('watchers', 0):,}")
        lines.append(f"- ğŸ› Open Issuesï¼š{metrics.get('open_issues', 0):,}")
        lines.append(f"- ğŸ‘¥ è´¡çŒ®è€…ï¼š{metrics.get('contributors', 0)}")
        if metrics.get("latest_release"):
            lines.append(f"- ğŸ“¦ æœ€æ–°ç‰ˆæœ¬ï¼š{metrics['latest_release']}")
        if metrics.get("commit_frequency"):
            lines.append(f"- ğŸ“ˆ æäº¤é¢‘ç‡ï¼š{metrics['commit_frequency']}")
        lines.append("")

    # æŠ€æœ¯æ ˆ
    tech_stack = results.get("tech_stack", [])
    if tech_stack:
        lines.append("## æŠ€æœ¯æ ˆ")
        lines.append("")
        lines.append("| è¯­è¨€ | å æ¯” |")
        lines.append("|------|------|")
        for lang in tech_stack[:5]:
            lines.append(f"| {lang['language']} | {lang['percentage']}% |")
        lines.append("")

    # æ ¸å¿ƒåŠŸèƒ½
    features = results.get("key_features", [])
    if features:
        lines.append("## æ ¸å¿ƒåŠŸèƒ½")
        lines.append("")
        for feature in features:
            lines.append(f"- {feature}")
        lines.append("")

    # æ¶æ„äº®ç‚¹
    arch = results.get("architecture_highlights", [])
    if arch:
        lines.append("## æ¶æ„äº®ç‚¹")
        lines.append("")
        for highlight in arch:
            lines.append(f"- {highlight}")
        lines.append("")

    # README æ‘˜è¦
    readme_summary = results.get("readme_summary", "")
    if readme_summary:
        lines.append("## README æ‘˜è¦")
        lines.append("")
        lines.append(readme_summary)
        lines.append("")

    # ç®€å†å‚è€ƒå»ºè®®
    lines.append("## ç®€å†å‚è€ƒä»·å€¼")
    lines.append("")
    lines.append("ä»è¯¥é¡¹ç›®å¯ä»¥å‚è€ƒçš„æŠ€æœ¯æè¿°ï¼š")
    lines.append("")
    if tech_stack:
        main_langs = [t["language"] for t in tech_stack[:3]]
        lines.append(f"- æŠ€æœ¯æ ˆï¼š{', '.join(main_langs)}")
    if features:
        lines.append(f"- å¯å€Ÿé‰´çš„åŠŸèƒ½æè¿°ï¼š")
        for f in features[:3]:
            lines.append(f"  - {f}")
    if metrics.get("stars", 0) > 10000:
        lines.append(f"- è¿™æ˜¯ä¸€ä¸ªé«˜ Star é¡¹ç›®ï¼Œå¦‚æœä½ æœ‰ç±»ä¼¼ç»éªŒå¯ä»¥å¯¹æ ‡æè¿°")
    lines.append("")

    return "\n".join(lines)
